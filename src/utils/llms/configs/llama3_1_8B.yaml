config:
  model_name: meta-llama/Llama-3.1-8B-Instruct
  max_tokens: 8192